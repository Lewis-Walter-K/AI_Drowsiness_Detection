{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fa1f6e",
   "metadata": {},
   "source": [
    "# process_data - batch feature extraction\n",
    "This notebook processes all images under `Datasets_train/`, computes features using the same formulas as `real_time_demo.py`, saves up to 10 annotated previews per class into `Outputs/previews/`, and writes `Outputs/training-feature.csv` with columns:\n",
    "[EAR, MAR, PITCH, YAW, ROLL, D_SLUMP, R_TILT, EYE_CL, FACIAL_DISPLAYED, POSE_DISPLAYED, LABEL, Image_Path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7738f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6f78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and constants\n",
    "import os, math, cv2, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    TASKS_AVAILABLE = True\n",
    "except Exception:\n",
    "    import mediapipe as mp\n",
    "    TASKS_AVAILABLE = False\n",
    "\n",
    "# Landmark indices\n",
    "RIGHT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
    "LEFT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH_INDICES = [61, 291, 0, 17]\n",
    "\n",
    "# UPDATED: Set Dummy Value to 0.0 to match Scaler expectations\n",
    "DUMMY_VALUE = 0.0 \n",
    "\n",
    "# Paths\n",
    "ROOT = os.path.abspath('.')\n",
    "# UPDATED: Point to the new dataset folder\n",
    "DATA_ROOT = os.path.join(ROOT, 'Datasets_ReRecorded') \n",
    "OUTPUT_DIR = os.path.join(ROOT, 'Outputs')\n",
    "PREVIEW_DIR = os.path.join(OUTPUT_DIR, 'previews')\n",
    "os.makedirs(PREVIEW_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f49110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: EAR, MAR, head-pose, slump (same formulas as real_time_demo.py)\n",
    "def eye_aspect_ratio(eye_coords):\n",
    "    p1, p2, p3, p4, p5, p6 = eye_coords\n",
    "    vertical_1 = dist.euclidean(p2, p6)\n",
    "    vertical_2 = dist.euclidean(p3, p5)\n",
    "    horizontal = dist.euclidean(p1, p4)\n",
    "    if horizontal == 0: return 0.001\n",
    "    return (vertical_1 + vertical_2) / (2.0 * horizontal)\n",
    "\n",
    "def mouth_aspect_ratio(mouth_coords):\n",
    "    p1_h, p4_h, p2_v, p6_v = mouth_coords\n",
    "    vertical = dist.euclidean(p2_v, p6_v)\n",
    "    horizontal = dist.euclidean(p1_h, p4_h)\n",
    "    if horizontal == 0: return 0.001\n",
    "    return vertical / horizontal\n",
    "\n",
    "def calculate_geometric_head_pose(landmarks, w, h, overlay=None):\n",
    "    try:\n",
    "        nose = landmarks[1]\n",
    "        left_eye_outer = landmarks[33]\n",
    "        right_eye_outer = landmarks[263]\n",
    "        mouth_center = landmarks[13]\n",
    "        nx, ny = nose.x * w, nose.y * h\n",
    "        lx, ly = left_eye_outer.x * w, left_eye_outer.y * h\n",
    "        rx, ry = right_eye_outer.x * w, right_eye_outer.y * h\n",
    "        mx, my = mouth_center.x * w, mouth_center.y * h\n",
    "        if overlay is not None:\n",
    "            try: cv2.line(overlay, (int(lx), int(ly)), (int(rx), int(ry)), (255,0,255), 2)\n",
    "            except Exception: pass\n",
    "        dY = ry - ly\n",
    "        dX = rx - lx if (rx - lx) != 0 else 1e-6\n",
    "        roll = math.degrees(math.atan2(dY, dX))\n",
    "        dist_l = math.hypot(nx - lx, ny - ly)\n",
    "        dist_r = math.hypot(nx - rx, ny - ry)\n",
    "        yaw = ((dist_l - dist_r) / (dist_l + dist_r + 1e-6)) * 150\n",
    "        ex, ey = (lx + rx) / 2, (ly + ry) / 2\n",
    "        dist_nose_eyes = math.hypot(nx - ex, ny - ey)\n",
    "        dist_nose_mouth = math.hypot(nx - mx, ny - my) + 1e-6\n",
    "        pitch = (dist_nose_eyes / dist_nose_mouth - 1.0) * 100\n",
    "        return pitch, yaw, roll\n",
    "    except Exception:\n",
    "        return DUMMY_VALUE, DUMMY_VALUE, DUMMY_VALUE\n",
    "\n",
    "def calculate_slump_geometry(pose_landmarks, face_landmarks, w, h, overlay=None):\n",
    "    if not pose_landmarks: return DUMMY_VALUE, DUMMY_VALUE\n",
    "    try:\n",
    "        p_nose = pose_landmarks[0]\n",
    "        p_left_sh = pose_landmarks[11]\n",
    "        p_right_sh = pose_landmarks[12]\n",
    "        x_n, y_n = int(p_nose.x * w), int(p_nose.y * h)\n",
    "        x_l, y_l = int(p_left_sh.x * w), int(p_left_sh.y * h)\n",
    "        x_r, y_r = int(p_right_sh.x * w), int(p_right_sh.y * h)\n",
    "        mx, my = int((x_l + x_r) / 2), int((y_l + y_r) / 2)\n",
    "        if overlay is not None:\n",
    "            try:\n",
    "                cv2.line(overlay, (x_l, y_l), (x_r, y_r), (255,0,0), 3)\n",
    "                cv2.line(overlay, (x_n, y_n), (mx, my), (0,255,255), 3)\n",
    "            except Exception: pass\n",
    "        dY = y_l - y_r\n",
    "        dX = x_l - x_r if (x_l - x_r) != 0 else 1e-6\n",
    "        r_tilt = math.degrees(math.atan2(dY, dX))\n",
    "        if face_landmarks:\n",
    "            chin_y = face_landmarks[152].y * h\n",
    "            head_top_y = face_landmarks[10].y * h\n",
    "            face_h = abs(chin_y - head_top_y)\n",
    "            if face_h < 1: face_h = 1\n",
    "            d_slump = (my - y_n) / face_h\n",
    "        else:\n",
    "            d_slump = DUMMY_VALUE\n",
    "        return d_slump, r_tilt\n",
    "    except Exception:\n",
    "        return DUMMY_VALUE, DUMMY_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bcf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process single image and return features in required order; also save annotated preview when requested\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "def process_and_annotate(image_path, save_preview=True, preview_dir=PREVIEW_DIR):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f'Cannot read image: {image_path}')\n",
    "    h, w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1) as fm, \\\n",
    "         mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pm:\n",
    "        \n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        fres = fm.process(rgb)\n",
    "        pres = pm.process(rgb)\n",
    "        \n",
    "        # --- LOGIC CHANGE 1: STRICT FILTERING ---\n",
    "        # If no face is detected, we return NONE. We do not want this image.\n",
    "        if not fres.multi_face_landmarks:\n",
    "            return None, None\n",
    "\n",
    "        face_detected = True\n",
    "        face_lms = fres.multi_face_landmarks[0]\n",
    "        \n",
    "        pose_detected = bool(getattr(pres, 'pose_landmarks', None))\n",
    "        pose_lms = pres.pose_landmarks if pose_detected else None\n",
    "\n",
    "        # Draw face mesh (Visual only)\n",
    "        try:\n",
    "            mp_drawing.draw_landmarks(\n",
    "            image=overlay, landmark_list=face_lms, \n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION, \n",
    "            landmark_drawing_spec=None, \n",
    "            connection_drawing_spec=mp_styles.get_default_face_mesh_tesselation_style())\n",
    "        except Exception: pass\n",
    "\n",
    "        # --- Calculate Face Features ---\n",
    "        fl = face_lms.landmark\n",
    "        pts = [(lm.x * w, lm.y * h) for lm in fl]\n",
    "        \n",
    "        try:\n",
    "            left_eye = [pts[i] for i in LEFT_EYE_INDICES]\n",
    "            right_eye = [pts[i] for i in RIGHT_EYE_INDICES]\n",
    "            ear = (eye_aspect_ratio(left_eye) + eye_aspect_ratio(right_eye)) / 2.0\n",
    "        except: ear = 0.0\n",
    "            \n",
    "        try:\n",
    "            mouth_pts = [pts[i] for i in MOUTH_INDICES]\n",
    "            mar = mouth_aspect_ratio(mouth_pts)\n",
    "        except: mar = 0.0\n",
    "            \n",
    "        # try:\n",
    "        #     # Eye Circularity (Optional - we keep it for now as requested)\n",
    "        #     eye_v = (dist.euclidean(left_eye[1], left_eye[5]) + dist.euclidean(right_eye[1], right_eye[5])) / 2.0\n",
    "        #     xs = [p[0] for p in pts]\n",
    "        #     face_w = (max(xs) - min(xs)) if xs else 1.0\n",
    "        #     eye_closure = eye_v / (face_w + 1e-6)\n",
    "        # except: eye_closure = 0.0\n",
    "            \n",
    "        try: pitch, yaw, roll = calculate_geometric_head_pose(fl, w, h, overlay)\n",
    "        except: pitch = yaw = roll = 0.0\n",
    "\n",
    "        # --- LOGIC CHANGE 2: BODY IMPUTATION ---\n",
    "        if pose_detected and pose_lms is not None:\n",
    "            try:\n",
    "                pl = pose_lms.landmark\n",
    "                d_slump, r_tilt = calculate_slump_geometry(pl, fl, w, h, overlay)\n",
    "            except: \n",
    "                d_slump, r_tilt = 0.8, 0.0 # Default if calculation fails\n",
    "        else:\n",
    "            # BODY MISSING? Use \"Healthy\" Defaults\n",
    "            d_slump = 0.8  # Average upright sitting value\n",
    "            r_tilt = 0.0   # Straight shoulders\n",
    "            \n",
    "        # Annotate text\n",
    "        texts = [\n",
    "            f'EAR:{ear:.2f} MAR:{mar:.2f}',\n",
    "            f'P:{pitch:.1f} Y:{yaw:.1f} R:{roll:.1f}',\n",
    "            f'SLUMP:{d_slump:.2f} TILT:{r_tilt:.1f}'\n",
    "        ]\n",
    "        for i, t in enumerate(texts):\n",
    "            cv2.putText(overlay, t, (10, 30 + i*18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
    "\n",
    "        if save_preview:\n",
    "            outname = os.path.basename(image_path)\n",
    "            outpath = os.path.join(preview_dir, outname)\n",
    "            try: cv2.imwrite(outpath, overlay)\n",
    "            except: pass\n",
    "\n",
    "        # Return Features\n",
    "        features = [\n",
    "            round(ear, 4), round(mar, 4), \n",
    "            round(pitch, 4), round(yaw, 4), round(roll, 4), \n",
    "            round(d_slump, 4), round(r_tilt, 4), \n",
    "            int(face_detected), int(pose_detected)\n",
    "        ]\n",
    "        return features, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdfc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Awake (label=0) - 4146 images\n",
      "Processing Sleep (label=1) - 4137 images\n",
      "Processing Yawning (label=2) - 4119 images\n",
      "SUCCESS: Processed 11459 images.\n",
      "Saved to: c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Outputs\\final.csv\n",
      "\n",
      "--- Final Class Distribution ---\n",
      "LABEL\n",
      "0    4129\n",
      "1    3709\n",
      "2    3621\n",
      "Name: count, dtype: int64\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Batch processor: iterate dataset folders, process images, save up to 10 previews per class, export CSV\n",
    "desired_map = {'Awake': 0, 'Sleep': 1, 'Yawning': 2}\n",
    "\n",
    "rows = []\n",
    "preview_counts = {v:0 for v in desired_map.values()}\n",
    "\n",
    "# Walk dataset folders\n",
    "for folder in sorted(os.listdir(DATA_ROOT)):\n",
    "    folder_path = os.path.join(DATA_ROOT, folder)\n",
    "    if not os.path.isdir(folder_path): continue\n",
    "\n",
    "    label = desired_map.get(folder, None)\n",
    "    if label is None:\n",
    "        print('Skipping unknown folder (no mapping):', folder)\n",
    "        continue\n",
    "\n",
    "    imgs = [f for f in sorted(os.listdir(folder_path)) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp'))]\n",
    "    print(f'Processing {folder} (label={label}) - {len(imgs)} images')\n",
    "\n",
    "    saved_for_class = 0\n",
    "\n",
    "    for fname in imgs:\n",
    "        path = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            save_preview = (preview_counts[label] < 10)\n",
    "            \n",
    "            # Call function\n",
    "            result = process_and_annotate(path, save_preview=save_preview, preview_dir=PREVIEW_DIR)\n",
    "\n",
    "            # UPDATED: Check if image was skipped (No Face)\n",
    "            if result is None or result[0] is None:\n",
    "                continue\n",
    "\n",
    "            features, overlay = result\n",
    "            \n",
    "            if save_preview:\n",
    "                preview_counts[label] += 1\n",
    "\n",
    "            row = {\n",
    "                'EAR': features[0], 'MAR': features[1], \n",
    "                'PITCH': features[2], 'YAW': features[3], \n",
    "                'ROLL': features[4], 'D_SLUMP': features[5], \n",
    "                'R_TILT': features[6], 'FACIAL_DISPLAYED': features[7], \n",
    "                'POSE_DISPLAYED': features[8], 'LABEL': label, 'Image_Path': path\n",
    "            }\n",
    "            rows.append(row)\n",
    "        except Exception as e:\n",
    "            print('Skipped', path, '->', e)\n",
    "\n",
    "# Export CSV\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # 1. Rounding (Sanity Check)\n",
    "    for c in ['EAR','MAR','PITCH','YAW','ROLL','D_SLUMP','R_TILT']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(float).round(4)\n",
    "\n",
    "    # 2. Save the Raw Export (Good for backup)\n",
    "    out_csv = os.path.join(OUTPUT_DIR, 'training-feature.csv')\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    \n",
    "    # 3. Save the FINAL File (For the Training Model)\n",
    "    # We use this one in model_Khang.ipynb\n",
    "    additional_csv = os.path.join(OUTPUT_DIR, 'additional.csv')\n",
    "    df.to_csv(additional_csv, index=False)\n",
    "    \n",
    "    print(f\"SUCCESS: Processed {len(df)} images.\")\n",
    "    print(f\"Saved to: {additional_csv}\")\n",
    "    \n",
    "    # 4. Final Class Count Check (Important!)\n",
    "    print(\"\\n--- Final Class Distribution ---\")\n",
    "    print(df['LABEL'].value_counts())\n",
    "    print(\"--------------------------------\")\n",
    "else:\n",
    "    print('No rows to export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328d5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Outputs/training-feature.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb0760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "343d773c-f873-4fff-875f-eee16ff91f75",
       "rows": [
        [
         "EAR",
         "0"
        ],
        [
         "MAR",
         "0"
        ],
        [
         "PITCH",
         "0"
        ],
        [
         "YAW",
         "0"
        ],
        [
         "ROLL",
         "0"
        ],
        [
         "D_SLUMP",
         "0"
        ],
        [
         "R_TILT",
         "0"
        ],
        [
         "FACIAL_DISPLAYED",
         "0"
        ],
        [
         "POSE_DISPLAYED",
         "0"
        ],
        [
         "LABEL",
         "0"
        ],
        [
         "Image_Path",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/plain": [
       "EAR                 0\n",
       "MAR                 0\n",
       "PITCH               0\n",
       "YAW                 0\n",
       "ROLL                0\n",
       "D_SLUMP             0\n",
       "R_TILT              0\n",
       "FACIAL_DISPLAYED    0\n",
       "POSE_DISPLAYED      0\n",
       "LABEL               0\n",
       "Image_Path          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['FACIAL_DISPLAYED'] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46174ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by LABEL after filtering: LABEL\n",
      "0    4129\n",
      "1    3709\n",
      "2    3621\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter dataframe:\n",
    "# 1) Drop any images with LABEL==2 (Yawning) when FACIAL_DISPLAYED == 0\n",
    "# 2) Change LABEL from 1 (Sleep) to 3 (Passed_out) when FACIAL_DISPLAYED == 0\n",
    "df_filtered = df.copy()\n",
    "# Drop rows where label==2 and no face displayed\n",
    "df_filtered = df_filtered[~((df_filtered['LABEL'] == 2) & (df_filtered['FACIAL_DISPLAYED'] == 0))]\n",
    "# Relabel rows where label==1 and no face displayed -> 3\n",
    "mask = (df_filtered['LABEL'] == 1) & (df_filtered['FACIAL_DISPLAYED'] == 0)\n",
    "if mask.any():\n",
    "    df_filtered.loc[mask, 'LABEL'] = 3\n",
    "# Summary counts after filtering\n",
    "print('Counts by LABEL after filtering:', df_filtered['LABEL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9907036f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "771c9bf5-f898-4b03-b213-245121f14fd8",
       "rows": [
        [
         "EAR",
         "4129"
        ],
        [
         "MAR",
         "4129"
        ],
        [
         "PITCH",
         "4129"
        ],
        [
         "YAW",
         "4129"
        ],
        [
         "ROLL",
         "4129"
        ],
        [
         "D_SLUMP",
         "4129"
        ],
        [
         "R_TILT",
         "4129"
        ],
        [
         "FACIAL_DISPLAYED",
         "4129"
        ],
        [
         "POSE_DISPLAYED",
         "4129"
        ],
        [
         "LABEL",
         "4129"
        ],
        [
         "Image_Path",
         "4129"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/plain": [
       "EAR                 4129\n",
       "MAR                 4129\n",
       "PITCH               4129\n",
       "YAW                 4129\n",
       "ROLL                4129\n",
       "D_SLUMP             4129\n",
       "R_TILT              4129\n",
       "FACIAL_DISPLAYED    4129\n",
       "POSE_DISPLAYED      4129\n",
       "LABEL               4129\n",
       "Image_Path          4129\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[(df_filtered[\"LABEL\"] == 0) & (df_filtered[\"FACIAL_DISPLAYED\"] == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba47097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finalize numeric columns and export CSVs\n",
    "# df_filtered.iloc[:, 0:8] = df_filtered.iloc[:, 0:8].round(4)\n",
    "# # keep the original training-feature export (OUTPUT_CSV) and also write the final.csv as requested\n",
    "# df_filtered.to_csv(OUTPUT_CSV, index=False)\n",
    "# OUTPUT_FINAL = os.path.join(OUTPUT_DIR, 'final.csv')\n",
    "# df_filtered.to_csv(OUTPUT_FINAL, index=False)\n",
    "# print('Wrote', OUTPUT_CSV, 'and', OUTPUT_FINAL, 'rows:', len(df_filtered))\n",
    "# display(df_filtered.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
