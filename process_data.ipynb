{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fa1f6e",
   "metadata": {},
   "source": [
    "# process_data - batch feature extraction\n",
    "This notebook processes all images under `Datasets_train/`, computes features using the same formulas as `real_time_demo.py`, saves up to 10 annotated previews per class into `Outputs/previews/`, and writes `Outputs/training-feature.csv` with columns:\n",
    "[EAR, MAR, PITCH, YAW, ROLL, D_SLUMP, R_TILT, EYE_CL, FACIAL_DISPLAYED, POSE_DISPLAYED, LABEL, Image_Path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and constants\n",
    "import os, math, cv2, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    TASKS_AVAILABLE = True\n",
    "except Exception:\n",
    "    import mediapipe as mp\n",
    "    TASKS_AVAILABLE = False\n",
    "\n",
    "# Landmark indices\n",
    "RIGHT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
    "LEFT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH_INDICES = [61, 291, 0, 17]\n",
    "\n",
    "# UPDATED: Set Dummy Value to 0.0 to match Scaler expectations\n",
    "DUMMY_VALUE = 0.0 \n",
    "\n",
    "# Paths\n",
    "ROOT = os.path.abspath('.')\n",
    "# UPDATED: Point to the new dataset folder\n",
    "DATA_ROOT = os.path.join(ROOT, 'Datasets_ReRecorded') \n",
    "OUTPUT_DIR = os.path.join(ROOT, 'Outputs')\n",
    "PREVIEW_DIR = os.path.join(OUTPUT_DIR, 'previews')\n",
    "os.makedirs(PREVIEW_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f49110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: EAR, MAR, head-pose, slump (same formulas as real_time_demo.py)\n",
    "def eye_aspect_ratio(eye_coords):\n",
    "    p1, p2, p3, p4, p5, p6 = eye_coords\n",
    "    vertical_1 = dist.euclidean(p2, p6)\n",
    "    vertical_2 = dist.euclidean(p3, p5)\n",
    "    horizontal = dist.euclidean(p1, p4)\n",
    "    if horizontal == 0: return 0.001\n",
    "    return (vertical_1 + vertical_2) / (2.0 * horizontal)\n",
    "\n",
    "def mouth_aspect_ratio(mouth_coords):\n",
    "    p1_h, p4_h, p2_v, p6_v = mouth_coords\n",
    "    vertical = dist.euclidean(p2_v, p6_v)\n",
    "    horizontal = dist.euclidean(p1_h, p4_h)\n",
    "    if horizontal == 0: return 0.001\n",
    "    return vertical / horizontal\n",
    "\n",
    "def calculate_geometric_head_pose(landmarks, w, h, overlay=None):\n",
    "    try:\n",
    "        nose = landmarks[1]\n",
    "        left_eye_outer = landmarks[33]\n",
    "        right_eye_outer = landmarks[263]\n",
    "        mouth_center = landmarks[13]\n",
    "        nx, ny = nose.x * w, nose.y * h\n",
    "        lx, ly = left_eye_outer.x * w, left_eye_outer.y * h\n",
    "        rx, ry = right_eye_outer.x * w, right_eye_outer.y * h\n",
    "        mx, my = mouth_center.x * w, mouth_center.y * h\n",
    "        if overlay is not None:\n",
    "            try: cv2.line(overlay, (int(lx), int(ly)), (int(rx), int(ry)), (255,0,255), 2)\n",
    "            except Exception: pass\n",
    "        dY = ry - ly\n",
    "        dX = rx - lx if (rx - lx) != 0 else 1e-6\n",
    "        roll = math.degrees(math.atan2(dY, dX))\n",
    "        dist_l = math.hypot(nx - lx, ny - ly)\n",
    "        dist_r = math.hypot(nx - rx, ny - ry)\n",
    "        yaw = ((dist_l - dist_r) / (dist_l + dist_r + 1e-6)) * 150\n",
    "        ex, ey = (lx + rx) / 2, (ly + ry) / 2\n",
    "        dist_nose_eyes = math.hypot(nx - ex, ny - ey)\n",
    "        dist_nose_mouth = math.hypot(nx - mx, ny - my) + 1e-6\n",
    "        pitch = (dist_nose_eyes / dist_nose_mouth - 1.0) * 100\n",
    "        return pitch, yaw, roll\n",
    "    except Exception:\n",
    "        return DUMMY_VALUE, DUMMY_VALUE, DUMMY_VALUE\n",
    "\n",
    "def calculate_slump_geometry(pose_landmarks, face_landmarks, w, h, overlay=None):\n",
    "    if not pose_landmarks: return DUMMY_VALUE, DUMMY_VALUE\n",
    "    try:\n",
    "        p_nose = pose_landmarks[0]\n",
    "        p_left_sh = pose_landmarks[11]\n",
    "        p_right_sh = pose_landmarks[12]\n",
    "        x_n, y_n = int(p_nose.x * w), int(p_nose.y * h)\n",
    "        x_l, y_l = int(p_left_sh.x * w), int(p_left_sh.y * h)\n",
    "        x_r, y_r = int(p_right_sh.x * w), int(p_right_sh.y * h)\n",
    "        mx, my = int((x_l + x_r) / 2), int((y_l + y_r) / 2)\n",
    "        if overlay is not None:\n",
    "            try:\n",
    "                cv2.line(overlay, (x_l, y_l), (x_r, y_r), (255,0,0), 3)\n",
    "                cv2.line(overlay, (x_n, y_n), (mx, my), (0,255,255), 3)\n",
    "            except Exception: pass\n",
    "        dY = y_l - y_r\n",
    "        dX = x_l - x_r if (x_l - x_r) != 0 else 1e-6\n",
    "        r_tilt = math.degrees(math.atan2(dY, dX))\n",
    "        if face_landmarks:\n",
    "            chin_y = face_landmarks[152].y * h\n",
    "            head_top_y = face_landmarks[10].y * h\n",
    "            face_h = abs(chin_y - head_top_y)\n",
    "            if face_h < 1: face_h = 1\n",
    "            d_slump = (my - y_n) / face_h\n",
    "        else:\n",
    "            d_slump = DUMMY_VALUE\n",
    "        return d_slump, r_tilt\n",
    "    except Exception:\n",
    "        return DUMMY_VALUE, DUMMY_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process single image and return features in required order; also save annotated preview when requested\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "def process_and_annotate(image_path, save_preview=True, preview_dir=PREVIEW_DIR):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f'Cannot read image: {image_path}')\n",
    "    h, w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1) as fm, \\\n",
    "         mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pm:\n",
    "        \n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        fres = fm.process(rgb)\n",
    "        pres = pm.process(rgb)\n",
    "        \n",
    "        # --- LOGIC CHANGE 1: STRICT FILTERING ---\n",
    "        # If no face is detected, we return NONE. We do not want this image.\n",
    "        if not fres.multi_face_landmarks:\n",
    "            return None, None\n",
    "\n",
    "        face_detected = True\n",
    "        face_lms = fres.multi_face_landmarks[0]\n",
    "        \n",
    "        pose_detected = bool(getattr(pres, 'pose_landmarks', None))\n",
    "        pose_lms = pres.pose_landmarks if pose_detected else None\n",
    "\n",
    "        # Draw face mesh (Visual only)\n",
    "        try:\n",
    "            mp_drawing.draw_landmarks(\n",
    "            image=overlay, landmark_list=face_lms, \n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION, \n",
    "            landmark_drawing_spec=None, \n",
    "            connection_drawing_spec=mp_styles.get_default_face_mesh_tesselation_style())\n",
    "        except Exception: pass\n",
    "\n",
    "        # --- Calculate Face Features ---\n",
    "        fl = face_lms.landmark\n",
    "        pts = [(lm.x * w, lm.y * h) for lm in fl]\n",
    "        \n",
    "        try:\n",
    "            left_eye = [pts[i] for i in LEFT_EYE_INDICES]\n",
    "            right_eye = [pts[i] for i in RIGHT_EYE_INDICES]\n",
    "            ear = (eye_aspect_ratio(left_eye) + eye_aspect_ratio(right_eye)) / 2.0\n",
    "        except: ear = 0.0\n",
    "            \n",
    "        try:\n",
    "            mouth_pts = [pts[i] for i in MOUTH_INDICES]\n",
    "            mar = mouth_aspect_ratio(mouth_pts)\n",
    "        except: mar = 0.0\n",
    "            \n",
    "        # try:\n",
    "        #     # Eye Circularity (Optional - we keep it for now as requested)\n",
    "        #     eye_v = (dist.euclidean(left_eye[1], left_eye[5]) + dist.euclidean(right_eye[1], right_eye[5])) / 2.0\n",
    "        #     xs = [p[0] for p in pts]\n",
    "        #     face_w = (max(xs) - min(xs)) if xs else 1.0\n",
    "        #     eye_closure = eye_v / (face_w + 1e-6)\n",
    "        # except: eye_closure = 0.0\n",
    "            \n",
    "        try: pitch, yaw, roll = calculate_geometric_head_pose(fl, w, h, overlay)\n",
    "        except: pitch = yaw = roll = 0.0\n",
    "\n",
    "        # --- LOGIC CHANGE 2: BODY IMPUTATION ---\n",
    "        if pose_detected and pose_lms is not None:\n",
    "            try:\n",
    "                pl = pose_lms.landmark\n",
    "                d_slump, r_tilt = calculate_slump_geometry(pl, fl, w, h, overlay)\n",
    "            except: \n",
    "                d_slump, r_tilt = 0.8, 0.0 # Default if calculation fails\n",
    "        else:\n",
    "            # BODY MISSING? Use \"Healthy\" Defaults\n",
    "            d_slump = 0.8  # Average upright sitting value\n",
    "            r_tilt = 0.0   # Straight shoulders\n",
    "            \n",
    "        # Annotate text\n",
    "        texts = [\n",
    "            f'EAR:{ear:.2f} MAR:{mar:.2f}',\n",
    "            f'P:{pitch:.1f} Y:{yaw:.1f} R:{roll:.1f}',\n",
    "            f'SLUMP:{d_slump:.2f} TILT:{r_tilt:.1f}'\n",
    "        ]\n",
    "        for i, t in enumerate(texts):\n",
    "            cv2.putText(overlay, t, (10, 30 + i*18), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
    "\n",
    "        if save_preview:\n",
    "            outname = os.path.basename(image_path)\n",
    "            outpath = os.path.join(preview_dir, outname)\n",
    "            try: cv2.imwrite(outpath, overlay)\n",
    "            except: pass\n",
    "\n",
    "        # Return Features\n",
    "        features = [\n",
    "            round(ear, 4), round(mar, 4), \n",
    "            round(pitch, 4), round(yaw, 4), round(roll, 4), \n",
    "            round(d_slump, 4), round(r_tilt, 4), \n",
    "            int(face_detected), int(pose_detected)\n",
    "        ]\n",
    "        return features, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdfc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Awake (label=0) - 422 images\n",
      "Processing Passed_out (label=3) - 237 images\n",
      "Processing Sleep (label=1) - 510 images\n",
      "Processing Yawning (label=2) - 892 images\n",
      "Wrote c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Outputs\\training-feature.csv rows= 2061\n"
     ]
    }
   ],
   "source": [
    "# Batch processor: iterate dataset folders, process images, save up to 10 previews per class, export CSV\n",
    "desired_map = {'Awake': 0, 'Sleep': 1, 'Yawning': 2}\n",
    "\n",
    "rows = []\n",
    "preview_counts = {v:0 for v in desired_map.values()}\n",
    "\n",
    "# Walk dataset folders\n",
    "for folder in sorted(os.listdir(DATA_ROOT)):\n",
    "    folder_path = os.path.join(DATA_ROOT, folder)\n",
    "    if not os.path.isdir(folder_path): continue\n",
    "\n",
    "    label = desired_map.get(folder, None)\n",
    "    if label is None:\n",
    "        print('Skipping unknown folder (no mapping):', folder)\n",
    "        continue\n",
    "\n",
    "    imgs = [f for f in sorted(os.listdir(folder_path)) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp'))]\n",
    "    print(f'Processing {folder} (label={label}) - {len(imgs)} images')\n",
    "\n",
    "    saved_for_class = 0\n",
    "\n",
    "    for fname in imgs:\n",
    "        path = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            save_preview = (preview_counts[label] < 10)\n",
    "            \n",
    "            # Call function\n",
    "            result = process_and_annotate(path, save_preview=save_preview, preview_dir=PREVIEW_DIR)\n",
    "\n",
    "            # UPDATED: Check if image was skipped (No Face)\n",
    "            if result is None or result[0] is None:\n",
    "                continue\n",
    "\n",
    "            features, overlay = result\n",
    "            \n",
    "            if save_preview:\n",
    "                preview_counts[label] += 1\n",
    "\n",
    "            row = {\n",
    "                'EAR': features[0], 'MAR': features[1], \n",
    "                'PITCH': features[2], 'YAW': features[3], \n",
    "                'ROLL': features[4], 'D_SLUMP': features[5], \n",
    "                'R_TILT': features[6], 'FACIAL_DISPLAYED': features[7], \n",
    "                'POSE_DISPLAYED': features[8], 'LABEL': label, 'Image_Path': path\n",
    "            }\n",
    "            rows.append(row)\n",
    "        except Exception as e:\n",
    "            print('Skipped', path, '->', e)\n",
    "\n",
    "# Export CSV\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # 1. Rounding (Sanity Check)\n",
    "    for c in ['EAR','MAR','PITCH','YAW','ROLL','D_SLUMP','R_TILT']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(float).round(4)\n",
    "\n",
    "    # 2. Save the Raw Export (Good for backup)\n",
    "    out_csv = os.path.join(OUTPUT_DIR, 'training-feature.csv')\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    \n",
    "    # 3. Save the FINAL File (For the Training Model)\n",
    "    # We use this one in model_Khang.ipynb\n",
    "    final_csv = os.path.join(OUTPUT_DIR, 'final.csv')\n",
    "    df.to_csv(final_csv, index=False)\n",
    "    \n",
    "    print(f\"SUCCESS: Processed {len(df)} images.\")\n",
    "    print(f\"Saved to: {final_csv}\")\n",
    "    \n",
    "    # 4. Final Class Count Check (Important!)\n",
    "    print(\"\\n--- Final Class Distribution ---\")\n",
    "    print(df['LABEL'].value_counts())\n",
    "    print(\"--------------------------------\")\n",
    "else:\n",
    "    print('No rows to export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "328d5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Outputs/training-feature.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cb0760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "52dbe508-3e43-47a9-8d64-47bd6d208f57",
       "rows": [
        [
         "EAR",
         "0"
        ],
        [
         "MAR",
         "0"
        ],
        [
         "PITCH",
         "0"
        ],
        [
         "YAW",
         "0"
        ],
        [
         "ROLL",
         "0"
        ],
        [
         "D_SLUMP",
         "0"
        ],
        [
         "R_TILT",
         "0"
        ],
        [
         "EYE_CL",
         "0"
        ],
        [
         "FACIAL_DISPLAYED",
         "0"
        ],
        [
         "POSE_DISPLAYED",
         "0"
        ],
        [
         "LABEL",
         "0"
        ],
        [
         "Image_Path",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "EAR                 0\n",
       "MAR                 0\n",
       "PITCH               0\n",
       "YAW                 0\n",
       "ROLL                0\n",
       "D_SLUMP             0\n",
       "R_TILT              0\n",
       "EYE_CL              0\n",
       "FACIAL_DISPLAYED    0\n",
       "POSE_DISPLAYED      0\n",
       "LABEL               0\n",
       "Image_Path          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['FACIAL_DISPLAYED'] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46174ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by LABEL after filtering: LABEL\n",
      "0    296\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter dataframe:\n",
    "# 1) Drop any images with LABEL==2 (Yawning) when FACIAL_DISPLAYED == 0\n",
    "# 2) Change LABEL from 1 (Sleep) to 3 (Passed_out) when FACIAL_DISPLAYED == 0\n",
    "df_filtered = df.copy()\n",
    "# Drop rows where label==2 and no face displayed\n",
    "df_filtered = df_filtered[~((df_filtered['LABEL'] == 2) & (df_filtered['FACIAL_DISPLAYED'] == 0))]\n",
    "# Relabel rows where label==1 and no face displayed -> 3\n",
    "mask = (df_filtered['LABEL'] == 1) & (df_filtered['FACIAL_DISPLAYED'] == 0)\n",
    "if mask.any():\n",
    "    df_filtered.loc[mask, 'LABEL'] = 3\n",
    "# Summary counts after filtering\n",
    "print('Counts by LABEL after filtering:', df_filtered['LABEL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9907036f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b5a91035-20d6-4f4b-b6ba-c08902462759",
       "rows": [
        [
         "EAR",
         "422"
        ],
        [
         "MAR",
         "422"
        ],
        [
         "PITCH",
         "422"
        ],
        [
         "YAW",
         "422"
        ],
        [
         "ROLL",
         "422"
        ],
        [
         "D_SLUMP",
         "422"
        ],
        [
         "R_TILT",
         "422"
        ],
        [
         "EYE_CL",
         "422"
        ],
        [
         "FACIAL_DISPLAYED",
         "422"
        ],
        [
         "POSE_DISPLAYED",
         "422"
        ],
        [
         "LABEL",
         "422"
        ],
        [
         "Image_Path",
         "422"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "EAR                 422\n",
       "MAR                 422\n",
       "PITCH               422\n",
       "YAW                 422\n",
       "ROLL                422\n",
       "D_SLUMP             422\n",
       "R_TILT              422\n",
       "EYE_CL              422\n",
       "FACIAL_DISPLAYED    422\n",
       "POSE_DISPLAYED      422\n",
       "LABEL               422\n",
       "Image_Path          422\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[(df_filtered[\"LABEL\"] == 0) & (df_filtered[\"FACIAL_DISPLAYED\"] == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Outputs\\training-feature.csv and c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Outputs\\final.csv rows: 2055\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EAR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PITCH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "YAW",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROLL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "D_SLUMP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R_TILT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "EYE_CL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FACIAL_DISPLAYED",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "POSE_DISPLAYED",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LABEL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image_Path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d401a8a4-30a2-49b2-974d-c80034fe3155",
       "rows": [
        [
         "0",
         "0.3331",
         "0.5861",
         "31.6382",
         "-5.2346",
         "-5.0504",
         "1.064",
         "0.507",
         "0.0621",
         "1",
         "1",
         "0",
         "c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Datasets_train\\Awake\\100_jpg.rf.8aabea6d0abf25becbe646f2be1e1063.jpg"
        ],
        [
         "1",
         "0.2696",
         "0.2103",
         "23.0431",
         "-1.6258",
         "-0.4376",
         "0.9222",
         "-1.8882",
         "0.0536",
         "1",
         "1",
         "0",
         "c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Datasets_train\\Awake\\101_jpg.rf.06718daabdc95ba1c7cb9e26980ff7b1.jpg"
        ],
        [
         "2",
         "0.4142",
         "0.2831",
         "145.9168",
         "0.9384",
         "-1.5578",
         "0.7423",
         "-1.2571",
         "0.0878",
         "1",
         "1",
         "0",
         "c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Datasets_train\\Awake\\102_jpg.rf.79d3552307a351354583dc47ca5ea0c0.jpg"
        ],
        [
         "3",
         "0.4271",
         "0.2635",
         "32.7882",
         "-25.6324",
         "3.5415",
         "1.0925",
         "4.0142",
         "0.0811",
         "1",
         "1",
         "0",
         "c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Datasets_train\\Awake\\103_jpg.rf.bae056751cb245670562b614e2b6c913.jpg"
        ],
        [
         "4",
         "0.359",
         "0.2906",
         "57.2217",
         "-1.0224",
         "-0.2451",
         "0.9877",
         "0.7673",
         "0.0683",
         "1",
         "1",
         "0",
         "c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsiness_Detection\\Datasets_train\\Awake\\104_jpg.rf.f85676cdb17a50ff2d066ad806bf3ec9.jpg"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>PITCH</th>\n",
       "      <th>YAW</th>\n",
       "      <th>ROLL</th>\n",
       "      <th>D_SLUMP</th>\n",
       "      <th>R_TILT</th>\n",
       "      <th>EYE_CL</th>\n",
       "      <th>FACIAL_DISPLAYED</th>\n",
       "      <th>POSE_DISPLAYED</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>31.6382</td>\n",
       "      <td>-5.2346</td>\n",
       "      <td>-5.0504</td>\n",
       "      <td>1.0640</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>23.0431</td>\n",
       "      <td>-1.6258</td>\n",
       "      <td>-0.4376</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>-1.8882</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.2831</td>\n",
       "      <td>145.9168</td>\n",
       "      <td>0.9384</td>\n",
       "      <td>-1.5578</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>-1.2571</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4271</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>32.7882</td>\n",
       "      <td>-25.6324</td>\n",
       "      <td>3.5415</td>\n",
       "      <td>1.0925</td>\n",
       "      <td>4.0142</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>57.2217</td>\n",
       "      <td>-1.0224</td>\n",
       "      <td>-0.2451</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EAR     MAR     PITCH      YAW    ROLL  D_SLUMP  R_TILT  EYE_CL  \\\n",
       "0  0.3331  0.5861   31.6382  -5.2346 -5.0504   1.0640  0.5070  0.0621   \n",
       "1  0.2696  0.2103   23.0431  -1.6258 -0.4376   0.9222 -1.8882  0.0536   \n",
       "2  0.4142  0.2831  145.9168   0.9384 -1.5578   0.7423 -1.2571  0.0878   \n",
       "3  0.4271  0.2635   32.7882 -25.6324  3.5415   1.0925  4.0142  0.0811   \n",
       "4  0.3590  0.2906   57.2217  -1.0224 -0.2451   0.9877  0.7673  0.0683   \n",
       "\n",
       "   FACIAL_DISPLAYED  POSE_DISPLAYED  LABEL  \\\n",
       "0                 1               1      0   \n",
       "1                 1               1      0   \n",
       "2                 1               1      0   \n",
       "3                 1               1      0   \n",
       "4                 1               1      0   \n",
       "\n",
       "                                          Image_Path  \n",
       "0  c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...  \n",
       "1  c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...  \n",
       "2  c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...  \n",
       "3  c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...  \n",
       "4  c:\\VGU_projects\\Drowsiness_detector\\AI_Drowsin...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Finalize numeric columns and export CSVs\n",
    "# df_filtered.iloc[:, 0:8] = df_filtered.iloc[:, 0:8].round(4)\n",
    "# # keep the original training-feature export (OUTPUT_CSV) and also write the final.csv as requested\n",
    "# df_filtered.to_csv(OUTPUT_CSV, index=False)\n",
    "# OUTPUT_FINAL = os.path.join(OUTPUT_DIR, 'final.csv')\n",
    "# df_filtered.to_csv(OUTPUT_FINAL, index=False)\n",
    "# print('Wrote', OUTPUT_CSV, 'and', OUTPUT_FINAL, 'rows:', len(df_filtered))\n",
    "# display(df_filtered.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
